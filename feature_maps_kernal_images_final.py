# -*- coding: utf-8 -*-
"""feature_maps_kernal_images_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eYhMkSkU6k6T6O-wsSt_LKu2xayT_Fdi
"""

import pandas as pd
import numpy as np
import os
import tensorflow as tf
import cv2
from tensorflow import keras
from tensorflow.keras.models import Model
from tensorflow.keras.models import load_model, Model
from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization, Input, GlobalMaxPooling3D, GlobalAveragePooling3D
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.utils import Sequence
from sklearn.model_selection import KFold, train_test_split
from tensorflow.keras import mixed_precision
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt


policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_global_policy(policy)


gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  try:
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
  except RuntimeError as e:
    print(e)

IMG_WIDTH, IMG_HEIGHT, IMG_DEPTH = 200, 200, 200
defined_value=[
    0.573,
    0.562,
    0.5795,
    0.5276,
    0.579,
    0.6115,
    0.5767,
    0.56,
    0.568,
    0.5505,
    0.5628,
    0.5241,
    0.5894,
    0.5738,
    0.5892,
    0.5439,
    0.5489,
    0.5692,
    0.5353,
    0.54,
    0.5572,
    0.5592,
    0.5725,
    0.5376,
    0.5438,
    0.5517,
    0.52,
    0.5575,
    0.5544,
    0.546,
    0.6317,
    0.6108,
    0.555,
    0.603,
    0.6311,
    0.6313,
    0.6106,
    0.6388,
    0.643,
    0.652,
]

class DataGenerator(Sequence):
    def __init__(self, dir_list, defined_values, img_folder='Negated_Images_Amplified', batch_size=16, shuffle=True):
        self.img_folder = img_folder
        self.defined_values = defined_values
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.dir_list = dir_list
        self.indexes = np.arange(len(self.dir_list))

    def __len__(self):
        return len(self.dir_list) // self.batch_size

    def __getitem__(self, index):
        print('Length of dir_list:', len(self.dir_list))
        print('Batch size:', self.batch_size)
        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        batch_dirs = [self.dir_list[k] for k in indexes]
        X, y = self.__data_generation(batch_dirs)
        return X, y

    def on_epoch_end(self):
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __data_generation(self, batch_dirs):
        X = np.empty((self.batch_size, 200, 200, 200, 1))
        y = np.empty((self.batch_size, 1))
        for i, dir_name in enumerate(batch_dirs):
            dir_path = os.path.join(self.img_folder, dir_name)
            file_list = sorted([f for f in os.listdir(dir_path) if f.endswith('.png')])
            image_array = np.empty((200, 200, 200))
            for j, file_name in enumerate(file_list):
                image = cv2.imread(os.path.join(dir_path, file_name))
                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                image = cv2.resize(image, (200, 200), interpolation = cv2.INTER_AREA)
                image = np.array(image)
                image = image.astype('float32')
                image /= 255
                image_array[:, :, j] = image
            X[i,] = np.expand_dims(image_array, axis=3)
            y[i] = self.defined_values[int(dir_name[2:]) % 40]
        return X, y



def create_model():
    model = Sequential([
        # Input layer
        Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu', input_shape=(200, 200, 200, 1), kernel_regularizer=l2(0.01)),
        # Output: 200 * 200 * 200 * 8

        # Pooling
        MaxPooling3D(pool_size=(2, 2, 2)),
        # Output: 100 * 100 * 100 * 8

        # Convolution layer
        Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu', kernel_regularizer=l2(0.01)),
        # Output: 100 * 100 * 100 * 16

        # Pooling
        MaxPooling3D(pool_size=(4, 4, 4)),
        # Output: 25 * 25 * 25 * 16

        # Convolution layer
        Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu', kernel_regularizer=l2(0.01)),
        # Output: 25 * 25 * 25 * 32

        # Pooling
        MaxPooling3D(pool_size=(2, 2, 2)),
        # Output: 12 * 12 * 12 * 32

        # Convolution layer
        Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu', kernel_regularizer=l2(0.01)),
        # Output: 12 * 12 * 12 * 64

        # Convolution layer
        Conv3D(filters=128, kernel_size=(3, 3, 3), activation='relu', kernel_regularizer=l2(0.01)),
        # Output: 12 * 12 * 12 * 128

        # Global Max Pooling
        GlobalMaxPooling3D(),
        # Output: 128

        # Flatten
        Flatten(),
        # Output: 128

        # Dense layers
        Dense(units=128, activation='relu', kernel_regularizer=l2(0.01)),
        Dense(units=32, activation='relu', kernel_regularizer=l2(0.01)),
        Dense(units=1, activation='sigmoid', kernel_regularizer=l2(0.01))
    ])

    # Compile
    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')

    return model
# Learning rate scheduler
def scheduler(epoch, lr):
    if epoch < 10:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

# Metrics Calculation
def calculate_metrics(y_true, y_pred):
    mse = np.mean((y_true - y_pred)**2)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    return mse, mape



import os
import tensorflow as tf
import matplotlib.pyplot as plt

def visualize_and_save_3d_kernels(model, input_shape=(200, 200, 200, 1)):
    # Create a directory to save the kernel images
    os.makedirs("kernel_images_3d", exist_ok=True)

    # Access the 3D convolutional layers
    cnn_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Conv3D)]

    # Extract kernel weights and save images
    for i, layer in enumerate(cnn_layers):
        # Get the kernel weights for the current layer
        kernel_weights = layer.get_weights()[0]
        num_filters = kernel_weights.shape[-1]

        # Save the kernel weights as images (assuming they have 1 channel)
        for j in range(num_filters):
            kernel_image = kernel_weights[:, :, :, :, j]
            plt.imshow(kernel_image[:, :, kernel_image.shape[2] // 2, 0], cmap='gray')  # Display a slice of the kernel
            plt.title(f"Layer {i+1}, Filter {j+1}")

            # Save the kernel image
            plt.savefig(f"kernel_images_3d/layer_{i+1}_filter_{j+1}.png")

            # Clear the figure to plot the next kernel
            plt.clf()

"""Generate and Save kernal images

"""

##

model = tf.keras.models.load_model('model.h5')

visualize_and_save_3d_kernels(model, input_shape=(200, 200, 200, 1))

"""Generate feature maps

"""

# Directory containing image data
data_dir = 'Negated_Images_Amplified/'

# List of directory names containing images
dir_list = os.listdir(data_dir)

# Define your defined_values (modify as needed)
defined_values = np.random.randint(2, size=len(dir_list))

data_generator = DataGenerator(dir_list, defined_values)

# Load the pre-trained model
model = load_model('model.h5')  # Replace with your model path

# Output directory for saving feature maps
output_dir = 'output'
os.makedirs(output_dir, exist_ok=True)
# Modify this list according to the layers you want to extract feature maps from
layer_names = ['conv3d_10', 'conv3d_11', 'conv3d_12', 'conv3d_13', 'conv3d_14']

# Extract and visualize feature maps
for x_batch, y_batch in data_generator:
    for layer_name in layer_names:
        intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
        feature_maps = intermediate_layer_model.predict(x_batch, batch_size=data_generator.batch_size)

        for i, feature_map in enumerate(feature_maps):
            output_file = os.path.join(output_dir, f"{y_batch[i]}_{layer_name}.npy")
            #np.save(output_file, feature_map)

            # Visualize the feature map
            plt.imshow(feature_map[0, :, :, 0], cmap='viridis')  # Adjust index and colormap as needed
            plt.title(f"Layer: {layer_name}, Class: {y_batch[i]}")

            # Save the plot as an image
            plot_image_file = os.path.join(output_dir, f"{y_batch[i]}_{layer_name}_plot.png")
            plt.savefig(plot_image_file)

            # Clear the current plot for the next iteration
            plt.clf()

